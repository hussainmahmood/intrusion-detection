{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ULRBIVQ3azLk"},"outputs":[],"source":["import sys\n","sys.path.insert(1, '../')\n","import pandas as pd\n","import numpy as np\n","from IPython.display import clear_output\n","import random\n","import seaborn as sb\n","import matplotlib.pyplot as plt\n","from genetic_selection import GeneticSelectionCV\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, classification_report, make_scorer\n","from sklearn.utils.validation import check_consistent_length"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def eval(X_train, y_train, X_test, y_test):\n","    model = MLPClassifier(hidden_layer_sizes=(128,128), activation=\"relu\", solver=\"adam\",\n","                          learning_rate=\"adaptive\", learning_rate_init=0.0003, \n","                          batch_size=64, max_iter=300, \n","                          early_stopping=True, n_iter_no_change=30)\n","    model.fit(X_train, y_train)\n","    y_preds = model.predict(X_test)\n","    print(\"\\nClassification report:\\n\")\n","    print(classification_report(y_test, y_preds))\n","    print(\"\\nConfusion matrix:\\n\")\n","    print(confusion_matrix(y_test, y_preds))\n","\n","    return (\n","        accuracy_score(y_test, y_preds)*100,\n","        precision_score(y_test, y_preds, average=\"weighted\")*100,\n","        recall_score(y_test, y_preds, average=\"weighted\")*100,\n","        f1_score(y_test, y_preds, average=\"weighted\")*100       \n","    )"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["df_train = pd.read_csv('../UNSW-NB15/cleaned_data/UNSW_NB15_training-set_cleaned.csv')\n","df_validation = pd.read_csv('../UNSW-NB15/cleaned_data/UNSW_NB15_validation-set_cleaned.csv')\n","df_test = pd.read_csv('../UNSW-NB15/cleaned_data/UNSW_NB15_testing-set_cleaned.csv')\n","X_train, y_train = df_train.iloc[:, 0:-2], df_train.iloc[:, -2]\n","X_validation, y_validation = df_validation.iloc[:, 0:-2], df_validation.iloc[:, -2]\n","X_test, y_test = df_test.iloc[:, 0:-2], df_test.iloc[:, -2]"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def genetic_selector(n_population, X_train, y_train, use_validation_set=False, X_validation=None, y_validation=None, verbose=0):\n","    selector = GeneticSelectionCV(\n","        estimator=ExtraTreeClassifier(), \n","        scoring=make_scorer(f1_score, average=\"weighted\"),\n","        n_population=n_population, \n","        n_generations=150, \n","        n_gen_no_change=30,\n","        verbose=verbose,\n","        n_jobs=-1\n","        )\n","    selector.fit(X_train, y_train, use_validation_set=use_validation_set, valid_X=X_validation, valid_y=y_validation)\n","    sel_features = sum([1 for support in selector.support_ if support])\n","    return selector, sel_features"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["result_df = pd.DataFrame(columns=[\"experiment\", \"pop_size\", \"features\", \"accuracy\", \"precision\", \"recall\", \"f1-score\"])\n","sb.set_theme()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Selecting features with genetic algorithm.\n","gen\tnevals\tavg                               \tstd                               \tmin                            \tmax                                  \n","0  \t80    \t[  0.715403  97.7625     0.      ]\t[  0.111685  54.516796   0.      ]\t[ 0.288971  3.        0.      ]\t[   0.780943  191.          0.      ]\n","1  \t49    \t[   0.76559  128.4375     0.     ]\t[  0.010233  35.895976   0.      ]\t[ 0.72995  8.       0.     ]   \t[   0.780943  190.          0.      ]\n","2  \t51    \t[   0.770703  143.8375      0.      ]\t[  0.007703  27.578725   0.      ]\t[  0.73246  75.        0.     ]\t[   0.783542  183.          0.      ]\n","3  \t50    \t[   0.772709  151.375       0.      ]\t[  0.00745   22.499653   0.      ]\t[  0.740476  79.         0.      ]\t[   0.785806  181.          0.      ]\n","4  \t46    \t[   0.77355  151.0875     0.     ]   \t[  0.009276  16.692209   0.      ]\t[   0.731291  107.          0.      ]\t[   0.785897  181.          0.      ]\n","5  \t52    \t[   0.777144  150.2125      0.      ]\t[  0.0067    16.055913   0.      ]\t[   0.749798  101.          0.      ]\t[   0.785897  181.          0.      ]\n","6  \t45    \t[   0.777648  150.6375      0.      ]\t[  0.008726  12.596868   0.      ]\t[   0.721061  103.          0.      ]\t[   0.785897  170.          0.      ]\n","7  \t49    \t[   0.778534  148.375       0.      ]\t[  0.006372  12.069978   0.      ]\t[   0.74856  110.         0.     ]   \t[   0.786708  166.          0.      ]\n","8  \t41    \t[   0.779813  149.9875      0.      ]\t[  0.007525  10.451667   0.      ]\t[   0.740567  125.          0.      ]\t[   0.787483  166.          0.      ]\n","9  \t41    \t[   0.781739  147.225       0.      ]\t[  0.004359  11.93731    0.      ]\t[   0.765729  123.          0.      ]\t[   0.787483  166.          0.      ]\n","10 \t53    \t[   0.779539  148.4         0.      ]\t[  0.006794  11.815879   0.      ]\t[   0.744006  125.          0.      ]\t[   0.787483  168.          0.      ]\n","11 \t41    \t[   0.78112  146.5375     0.     ]   \t[  0.005213  11.449829   0.      ]\t[   0.766109  123.          0.      ]\t[   0.787483  166.          0.      ]\n","12 \t49    \t[   0.781654  146.5625      0.      ]\t[  0.004652  11.625235   0.      ]\t[   0.771184  124.          0.      ]\t[   0.788237  166.          0.      ]\n","13 \t49    \t[   0.781697  143.875       0.      ]\t[  0.005884  10.946889   0.      ]\t[   0.752742  126.          0.      ]\t[   0.788237  166.          0.      ]\n","14 \t56    \t[   0.780192  142.15        0.      ]\t[  0.006593  11.156949   0.      ]\t[   0.752293  122.          0.      ]\t[   0.789165  165.          0.      ]\n","15 \t50    \t[   0.781701  143.2         0.      ]\t[  0.004729  11.494999   0.      ]\t[   0.767625  122.          0.      ]\t[   0.789165  160.          0.      ]\n"]}],"source":["for i in range(30):\n","    n_population = random.randint(80, 120)\n","    validation_selector, sel_features = genetic_selector(n_population, X_train, y_train, use_validation_set=True, X_validation=X_validation, y_validation=y_validation, verbose=1)\n","    X_train_valid_selected = validation_selector.transform(X_train)\n","    X_test_valid_selected = validation_selector.transform(X_test)\n","    result_df.loc[len(result_df.index)] = [int(i), n_population, sel_features, *eval(X_train_valid_selected, y_train, X_test_valid_selected, y_test)]\n","    result_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["result_dfm = pd.melt(result_df, id_vars=(\"experiment\"), value_vars=(\"accuracy\", \"precision\", \"recall\", \"f1-score\"), var_name=\"metric\", value_name=\"percentage\")\n","fig, ax1 = plt.subplots(figsize=(24, 4))\n","fig.suptitle(\"Comparison of different feature selections\")\n","sb.barplot(ax=ax1, data=result_dfm, x=\"experiment\", y=\"percentage\", hue=\"metric\", palette=[\"tab:red\", \"tab:green\", \"tab:orange\", \"tab:blue\"])\n","result_dfs = pd.melt(result_df, id_vars=(\"experiment\"), value_vars=(\"pop_size\", \"features\"), var_name=\"size\", value_name=\"sizes\")\n","sb.lineplot(ax=ax1, x=\"experiment\", y=\"sizes\", hue=\"size\", data=result_dfs, palette=[\"purple\", \"blue\"], marker='o')\n","ax1.legend(bbox_to_anchor=(1.04, 0.75), borderaxespad=0, title=\"Metrics\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["result_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["result_df[[\"pop_size\", \"accuracy\", \"recall\", \"precision\", \"f1-score\"]].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["result_df.to_csv('../output/test-3-result.csv', float_format='%f', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNcSFNbaEki0nEWT4TA4Yl4","gpuType":"T4","mount_file_id":"1wKwIynKtjwga26tzO9f4ADgwp7hHSAKk","provenance":[{"file_id":"1wKwIynKtjwga26tzO9f4ADgwp7hHSAKk","timestamp":1701810686302}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":0}
